#!/usr/bin/env python3
"""
è©³ç´°ãªã‚µã‚¤ãƒˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¾¿ã£ã¦å…¨è¨˜äº‹æ•°ã‚’å–å¾—
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import json

def analyze_pagination():
    """ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¾¿ã£ã¦è¨˜äº‹ç·æ•°ã‚’æŠŠæ¡"""
    base_url = "https://hidemiyoshi.jp/blog/"
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    })
    
    # æœ€çµ‚ãƒšãƒ¼ã‚¸ï¼ˆ45ãƒšãƒ¼ã‚¸ï¼‰ã‚’ç¢ºèª
    last_page_url = "https://hidemiyoshi.jp/blog/page/45"
    print(f"ğŸ” æœ€çµ‚ãƒšãƒ¼ã‚¸ã‚’ç¢ºèª: {last_page_url}")
    
    try:
        response = session.get(last_page_url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # è¨˜äº‹ãƒªãƒ³ã‚¯ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        articles = soup.find_all('article')
        articles_on_last_page = len(articles)
        
        # ã‚ˆã‚Šè©³ç´°ãªè¨˜äº‹è¦ç´ ã®æ¤œå‡º
        if articles_on_last_page == 0:
            # åˆ¥ã®æ–¹æ³•ã§è¨˜äº‹ã‚’æ¤œå‡º
            entry_titles = soup.find_all(class_=['entry-title', 'post-title'])
            articles_on_last_page = len(entry_titles)
        
        # ç·è¨˜äº‹æ•°ã®è¨ˆç®—ï¼ˆ44ãƒšãƒ¼ã‚¸ Ã— 10è¨˜äº‹ + æœ€çµ‚ãƒšãƒ¼ã‚¸ã®è¨˜äº‹æ•°ï¼‰
        total_articles = (44 * 10) + articles_on_last_page
        
        print(f"âœ… æœ€çµ‚ãƒšãƒ¼ã‚¸ã®è¨˜äº‹æ•°: {articles_on_last_page}")
        print(f"âœ… æ¨å®šç·è¨˜äº‹æ•°: {total_articles}")
        
        # é™¤å¤–å¯¾è±¡ã®è©³ç´°ç¢ºèª
        excluded_links = []
        for link in soup.find_all('a', href=True):
            href = link.get('href', '')
            if any(pattern in href for pattern in ['/wp-admin/', '/wp-login.php', '/feed/', '/?s=']):
                excluded_links.append(href)
        
        return {
            'total_pages': 45,
            'articles_on_last_page': articles_on_last_page,
            'estimated_total_articles': total_articles,
            'excluded_links_found': len(set(excluded_links))
        }
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def check_specific_resources():
    """ç‰¹å®šã®ãƒªã‚½ãƒ¼ã‚¹ã®è©³ç´°ç¢ºèª"""
    base_url = "https://hidemiyoshi.jp/blog/"
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    })
    
    print("\nğŸ“¦ ãƒªã‚½ãƒ¼ã‚¹ä¾å­˜é–¢ä¿‚ã®è©³ç´°èª¿æŸ»...")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹ãƒšãƒ¼ã‚¸ã‚’å–å¾—
    sample_url = "https://hidemiyoshi.jp/blog/2025/08/%e4%b9%85%e3%80%85%e3%83%88%e3%83%ac%e3%83%93%e3%83%a5%e3%83%ac%e3%83%bc%e3%83%88%e3%80%82hides%e3%81%aemma%e3%81%af%e3%81%93%e3%81%93%e3%81%8b%e3%82%89%e5%a7%8b%e3%81%be%e3%81%a3%e3%81%9f%e6%80%9d.html"
    
    try:
        response = session.get(sample_url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # jQueryä¾å­˜ã®ç¢ºèª
        jquery_scripts = [s for s in soup.find_all('script', src=True) if 'jquery' in s.get('src', '').lower()]
        
        # WordPressãƒ†ãƒ¼ãƒ/ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ç¢ºèª
        wp_resources = {
            'theme': [],
            'plugins': [],
            'core': []
        }
        
        for link in soup.find_all(['link', 'script'], src=True) + soup.find_all(['link', 'script'], href=True):
            url = link.get('src') or link.get('href', '')
            if '/wp-content/themes/' in url:
                wp_resources['theme'].append(url)
            elif '/wp-content/plugins/' in url:
                wp_resources['plugins'].append(url)
            elif '/wp-includes/' in url:
                wp_resources['core'].append(url)
        
        # å¤–éƒ¨åŸ‹ã‚è¾¼ã¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        embeds = []
        for iframe in soup.find_all('iframe'):
            src = iframe.get('src', '')
            if src:
                if 'youtube' in src.lower():
                    embeds.append({'type': 'YouTube', 'url': src})
                elif 'twitter' in src.lower() or 'x.com' in src:
                    embeds.append({'type': 'Twitter/X', 'url': src})
                elif 'instagram' in src.lower():
                    embeds.append({'type': 'Instagram', 'url': src})
                else:
                    embeds.append({'type': 'Other', 'url': src})
        
        return {
            'jquery_found': len(jquery_scripts) > 0,
            'jquery_scripts': [s.get('src') for s in jquery_scripts][:3],
            'wp_theme_resources': len(wp_resources['theme']),
            'wp_plugin_resources': len(wp_resources['plugins']),
            'wp_core_resources': len(wp_resources['core']),
            'external_embeds': embeds
        }
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    print("ğŸ”¬ è©³ç´°ã‚µã‚¤ãƒˆåˆ†æã‚’é–‹å§‹...")
    print("=" * 50)
    
    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ
    pagination_result = analyze_pagination()
    
    # ãƒªã‚½ãƒ¼ã‚¹è©³ç´°åˆ†æ
    resource_result = check_specific_resources()
    
    # çµæœã‚’ã¾ã¨ã‚ã‚‹
    final_report = {
        'pagination_analysis': pagination_result,
        'resource_analysis': resource_result
    }
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    with open('deep_analysis_report.json', 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 50)
    print("ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 50)
    
    if pagination_result:
        print(f"ğŸ“š ç·ãƒšãƒ¼ã‚¸æ•°: {pagination_result['total_pages']}ãƒšãƒ¼ã‚¸")
        print(f"ğŸ“ æ¨å®šç·è¨˜äº‹æ•°: {pagination_result['estimated_total_articles']}è¨˜äº‹")
    
    if resource_result:
        print(f"\nğŸ’» jQueryä½¿ç”¨: {'ã‚ã‚Š' if resource_result['jquery_found'] else 'ãªã—'}")
        print(f"ğŸ¨ ãƒ†ãƒ¼ãƒãƒªã‚½ãƒ¼ã‚¹: {resource_result['wp_theme_resources']}å€‹")
        print(f"ğŸ”Œ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒªã‚½ãƒ¼ã‚¹: {resource_result['wp_plugin_resources']}å€‹")
        print(f"ğŸ“¦ WordPressã‚³ã‚¢: {resource_result['wp_core_resources']}å€‹")
        
        if resource_result['external_embeds']:
            print("\nğŸŒ å¤–éƒ¨åŸ‹ã‚è¾¼ã¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„:")
            for embed in resource_result['external_embeds']:
                print(f"  - {embed['type']}: {embed['url'][:50]}...")
    
    print("\nâœ… è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ deep_analysis_report.json ã«ä¿å­˜ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()